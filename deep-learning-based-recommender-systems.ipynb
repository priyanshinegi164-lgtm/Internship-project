{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "   userId  movieId  rating           timestamp\n",
      "0       1        2     3.5 2005-04-02 23:53:47\n",
      "1       1       29     3.5 2005-04-02 23:31:16\n",
      "2       1       32     3.5 2005-04-02 23:33:39\n",
      "3       1       47     3.5 2005-04-02 23:32:07\n",
      "4       1       50     3.5 2005-04-02 23:29:40\n",
      "Total rows loaded:10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    ratings=pd.read_csv('rating.csv', parse_dates=['timestamp'], on_bad_lines='skip')\n",
    "    ratings=ratings.head(10000)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "    print(ratings.head())\n",
    "    print(f\"Total rows loaded:{len(ratings)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error:'rating.csv' not found. please ensure it is in the same directory as this notebook.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occured during file reading:{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3116 rows of data from 27 users\n"
     ]
    }
   ],
   "source": [
    "#using only 30% of users dataset\n",
    "rand_userIds = np.random.choice(ratings['userId'].unique(), size=int(len(ratings['userId'].unique())*0.3), replace=False)\n",
    "\n",
    "ratings = ratings.loc[ratings['userId'].isin(rand_userIds)]\n",
    "\n",
    "print('There are {} rows of data from {} users'.format(len(ratings), len(rand_userIds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>24</td>\n",
       "      <td>1682</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2001-07-04 07:04:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>54</td>\n",
       "      <td>2699</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-11-21 20:37:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>54</td>\n",
       "      <td>2161</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-11-21 19:56:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>5</td>\n",
       "      <td>631</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1996-12-25 15:17:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>54</td>\n",
       "      <td>2134</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2000-11-28 20:09:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId  movieId  rating           timestamp\n",
       "2725      24     1682     4.0 2001-07-04 07:04:07\n",
       "5905      54     2699     4.0 2000-11-21 20:37:46\n",
       "5793      54     2161     4.0 2000-11-21 19:56:29\n",
       "494        5      631     3.0 1996-12-25 15:17:36\n",
       "5786      54     2134     3.0 2000-11-28 20:09:51"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#train and test \n",
    "ratings['rank_latest'] = ratings.groupby(['userId'])['timestamp'] \\\n",
    "    .rank(method='first', ascending=False)\n",
    "\n",
    "train_ratings = ratings[ratings['rank_latest'] != 1]\n",
    "test_ratings = ratings[ratings['rank_latest'] == 1]\n",
    "\n",
    "# drop columns that we no longer need\n",
    "train_ratings = train_ratings[['userId', 'movieId', 'rating']]\n",
    "test_ratings = test_ratings[['userId', 'movieId', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7252</th>\n",
       "      <td>61</td>\n",
       "      <td>44397</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>24</td>\n",
       "      <td>3616</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9333</th>\n",
       "      <td>88</td>\n",
       "      <td>3686</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9407</th>\n",
       "      <td>89</td>\n",
       "      <td>2716</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8024</th>\n",
       "      <td>71</td>\n",
       "      <td>4022</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId  movieId  rating\n",
       "7252      61    44397     1.0\n",
       "2906      24     3616     1.0\n",
       "9333      88     3686     1.0\n",
       "9407      89     2716     1.0\n",
       "8024      71     4022     1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings.loc[:, 'rating'] = 1\n",
    "\n",
    "train_ratings.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fast Negative Sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Positive Samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3089/3089 [00:00<00:00, 515751.96it/s]\n",
      "Appending Negative Samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2259/2259 [00:00<00:00, 1900688.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive samples: 3089\n",
      "Total negative samples appended: 2259\n",
      "Total samples for training: 5348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all movie IDs\n",
    "all_movieIds = ratings['movieId'].unique()\n",
    "\n",
    "print(\"Starting Fast Negative Sampling...\")\n",
    "\n",
    "# Placeholders that will hold the final training data\n",
    "users, items, labels = [], [], []\n",
    "user_item_set = set(zip(train_ratings['userId'], train_ratings['movieId']))\n",
    "# Get the total number of positive interactions (for the loop)\n",
    "num_positive_samples = len(user_item_set)\n",
    "\n",
    "# 1. Process Positive Samples (Efficiently)\n",
    "for (u, i) in tqdm(user_item_set, desc=\"Processing Positive Samples\"):\n",
    "    users.append(u)\n",
    "    items.append(i)\n",
    "    labels.append(1) # Positive label\n",
    "\n",
    "# 2. Process Negative Samples (Optimized for Speed)\n",
    "# We need num_negatives * num_positive_samples total negative samples\n",
    "num_negatives=1\n",
    "total_negative_needed = num_negatives * num_positive_samples\n",
    "all_movieIds_array = np.array(all_movieIds)\n",
    "\n",
    "# Create a list to store all (user, negative_item) pairs\n",
    "negative_samples_list = []\n",
    "\n",
    "# For large datasets, a fixed batch approach is faster than checking every single sample.\n",
    "# We will generate a large pool and filter out the positives.\n",
    "\n",
    "# Create an array of user IDs, repeating each user ID 'num_negatives' times\n",
    "# Example: [u1, u1, u1, u2, u2, u2, ...]\n",
    "negative_user_ids = np.repeat(list(train_ratings['userId']), num_negatives)\n",
    "\n",
    "# Randomly select a large batch of movie IDs\n",
    "negative_movie_ids = np.random.choice(all_movieIds_array, size=len(negative_user_ids))\n",
    "\n",
    "# Zip the randomly generated pairs into a set for quick checking\n",
    "random_pairs_set = set(zip(negative_user_ids, negative_movie_ids))\n",
    "\n",
    "# Find the pairs that ARE positive samples (i.e., we need to reject them)\n",
    "bad_pairs = random_pairs_set.intersection(user_item_set)\n",
    "\n",
    "# Filter out the bad pairs to get a set of valid negative samples\n",
    "valid_negative_samples = random_pairs_set - bad_pairs\n",
    "\n",
    "\n",
    "# 3. Append the valid negative samples to the final lists\n",
    "# We only take the number of samples we originally intended to generate\n",
    "final_negative_samples = list(valid_negative_samples)[:total_negative_needed]\n",
    "\n",
    "for u, i in tqdm(final_negative_samples, desc=\"Appending Negative Samples\"):\n",
    "    users.append(u)\n",
    "    items.append(i)\n",
    "    labels.append(0) # Negative label\n",
    "\n",
    "print(f\"Total positive samples: {num_positive_samples}\")\n",
    "print(f\"Total negative samples appended: {len(final_negative_samples)}\")\n",
    "print(f\"Total samples for training: {len(users)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MovieLensTrainDataset(Dataset):\n",
    "    \"\"\"MovieLens PyTorch Dataset for Training\n",
    "    \n",
    "    Args:\n",
    "        ratings (pd.DataFrame): Dataframe containing the movie ratings\n",
    "        all_movieIds (list): List containing all movieIds\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ratings, all_movieIds):\n",
    "        self.users, self.items, self.labels = self.get_dataset(ratings, all_movieIds)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.labels[idx]\n",
    "\n",
    "    def get_dataset(self, ratings, all_movieIds):\n",
    "        users, items, labels = [], [], []\n",
    "        user_item_set = set(zip(ratings['userId'], ratings['movieId']))\n",
    "\n",
    "        num_negatives = 4\n",
    "        for u, i in user_item_set:\n",
    "            users.append(u)\n",
    "            items.append(i)\n",
    "            labels.append(1)\n",
    "            for _ in range(num_negatives):\n",
    "                negative_item = np.random.choice(all_movieIds)\n",
    "                while (u, negative_item) in user_item_set:\n",
    "                    negative_item = np.random.choice(all_movieIds)\n",
    "                users.append(u)\n",
    "                items.append(negative_item)\n",
    "                labels.append(0)\n",
    "\n",
    "        users_tensor=torch.tensor(users,dtype=torch.long)\n",
    "        items_tensor=torch.tensor(items,dtype=torch.long)\n",
    "        labels_tensor=torch.tensor(labels,dtype=torch.float32)\n",
    "        \n",
    "        return users_tensor, items_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#NCF model using Pytorch lightning\n",
    "class NCF(pl.LightningModule):\n",
    "    \"\"\" Neural Collaborative Filtering (NCF)\n",
    "    \n",
    "        Args:\n",
    "            num_users (int): Number of unique users\n",
    "            num_items (int): Number of unique items\n",
    "            ratings (pd.DataFrame): Dataframe containing the movie ratings for training\n",
    "            all_movieIds (list): List containing all movieIds (train + test)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_users, num_items, ratings, all_movieIds):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=8)\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=8)\n",
    "        self.fc1 = nn.Linear(in_features=16, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.output = nn.Linear(in_features=32, out_features=1)\n",
    "        self.ratings = ratings\n",
    "        self.all_movieIds = all_movieIds\n",
    "        \n",
    "    def forward(self, user_input, item_input):\n",
    "        \n",
    "        # Pass through embedding layers\n",
    "        user_embedded = self.user_embedding(user_input)\n",
    "        item_embedded = self.item_embedding(item_input)\n",
    "\n",
    "        # Concat the two embedding layers\n",
    "        vector = torch.cat([user_embedded, item_embedded], dim=-1)\n",
    "\n",
    "        # Pass through dense layer\n",
    "        vector = nn.ReLU()(self.fc1(vector))\n",
    "        vector = nn.ReLU()(self.fc2(vector))\n",
    "\n",
    "        # Output layer\n",
    "        pred = nn.Sigmoid()(self.output(vector))\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_input, item_input, labels = batch\n",
    "        predicted_labels = self(user_input, item_input)\n",
    "        loss = nn.BCELoss()(predicted_labels, labels.view(-1, 1).float())\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(MovieLensTrainDataset(self.ratings, self.all_movieIds),\n",
    "                          batch_size=512, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_users = ratings['userId'].max()+1\n",
    "num_items = ratings['movieId'].max()+1\n",
    "\n",
    "all_movieIds = ratings['movieId'].unique()\n",
    "\n",
    "model = NCF(num_users, num_items, train_ratings, all_movieIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name           | Type      | Params | Mode  | FLOPs\n",
      "-------------------------------------------------------------\n",
      "0 | user_embedding | Embedding | 720    | train | 0    \n",
      "1 | item_embedding | Embedding | 940 K  | train | 0    \n",
      "2 | fc1            | Linear    | 1.1 K  | train | 0    \n",
      "3 | fc2            | Linear    | 2.1 K  | train | 0    \n",
      "4 | output         | Linear    | 33     | train | 0    \n",
      "-------------------------------------------------------------\n",
      "944 K     Trainable params\n",
      "0         Non-trainable params\n",
      "944 K     Total params\n",
      "3.779     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n",
      "c:\\Users\\geeta\\.conda\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:434: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\geeta\\.conda\\envs\\pytorch_env\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:317: The number of training batches (31) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43046d75b8864ea9af975d5db333337e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "# Assuming NUM_EPOCHS = 2 or similar earlier\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    # 1. Standard Argument for epochs\n",
    "    max_epochs=2, \n",
    "    \n",
    "    # 2. Modern replacement for 'gpus' argument\n",
    "    accelerator=\"auto\", # Automatically detects and uses the best device (GPU or CPU)\n",
    "    devices=1,          # Uses 1 device \n",
    "    \n",
    "    # 3. Keep the logger for standard tracking\n",
    "    logger=True\n",
    "    \n",
    "    \n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<00:00, 71.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hit Ratio @ 10 is 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model\n",
    "# User-item pairs for testing\n",
    "import numpy as np\n",
    "test_user_item_set = set(zip(test_ratings['userId'], test_ratings['movieId']))\n",
    "\n",
    "# Dict of all items that are interacted with by each user\n",
    "user_interacted_items = ratings.groupby('userId')['movieId'].apply(list).to_dict()\n",
    "\n",
    "hits = []\n",
    "for (u,i) in tqdm(test_user_item_set):\n",
    "    interacted_items = user_interacted_items[u]\n",
    "    not_interacted_items = set(all_movieIds) - set(interacted_items)\n",
    "    selected_not_interacted = list(np.random.choice(list(not_interacted_items), 99))\n",
    "    test_items = selected_not_interacted + [i]\n",
    "    \n",
    "    user_input_tensor=torch.tensor([u]*100, dtype=torch.long)\n",
    "    item_input_tensor=torch.tensor(test_items,dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        predictions_tensor=model(user_input_tensor,item_input_tensor).squeeze()\n",
    "    top_k_values,top_k_indices=torch.topk(predictions_tensor, k=10, largest=True)\n",
    "    top10_items=[test_items[i]for i in top_k_indices.tolist()]\n",
    "    \n",
    "    if i in top10_items:\n",
    "        hits.append(1)\n",
    "    else:\n",
    "        hits.append(0)\n",
    "        \n",
    "print(\"The Hit Ratio @ 10 is {:.2f}\".format(np.average(hits)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
